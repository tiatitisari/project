{"cells":[{"source":"# Data Analyst Associate Practical Exam Submission\n\n**You can use any tool that you want to do your analysis and create visualizations. Use this template to write up your summary for submission.**\n\nYou can use any markdown formatting you wish. If you are not familiar with Markdown, read the [Markdown Guide](https://s3.amazonaws.com/talent-assets.datacamp.com/Markdown+Guide.pdf) before you start.\n\n","metadata":{"tags":[]},"id":"a5b3bc0e-b993-4ee3-bd07-825a474bd0d9","cell_type":"markdown"},{"source":"## Task 1\nQuestion: For every column in the data: \n- State whether the values match the description given in the table \n- State the number of missing values in the column \n- Describe what you did to make values match the description if they did not match \n","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]},"id":"d1b1a012-1ccb-40e7-a1ad-77b60b256690","cell_type":"markdown"},{"source":"First step is importing data from csv to dataframe and check the data type and data information. ","metadata":{},"cell_type":"markdown","id":"b46e63a3-0195-4d3c-aa88-3ee225110085"},{"source":"# Import data from csv to dataframe\nimport pandas as pd \nimport numpy as np \ndf = pd.DataFrame(pd.read_csv(\"food_claims_2212.csv\"))\n# Check several first rows of the data \nprint(df.head(5))\n# Check type of each column \nprint(df.info())\n# check missing value for each column \nprint(df.isna().sum())\n# check uniqueness of categorical column \nprint(df['location'].unique())\nprint(df['cause'].unique())","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1691808054050,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import data from csv to dataframe\nimport pandas as pd \nimport numpy as np \ndf = pd.DataFrame(pd.read_csv(\"food_claims_2212.csv\"))\n# Check several first rows of the data \nprint(df.head(5))\n# Check type of each column \nprint(df.info())\n# check missing value for each column \nprint(df.isna().sum())\n# check uniqueness of categorical column \nprint(df['location'].unique())\nprint(df['cause'].unique())","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"9ec8b9cf-12e5-457c-9bde-26f6d136aacc","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"   claim_id  time_to_close  ... linked_cases      cause\n0         1            317  ...        False    unknown\n1         2            195  ...         True    unknown\n2         3            183  ...         True       meat\n3         4            186  ...        False       meat\n4         5            138  ...        False  vegetable\n\n[5 rows x 8 columns]\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2000 entries, 0 to 1999\nData columns (total 8 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   claim_id              2000 non-null   int64  \n 1   time_to_close         2000 non-null   int64  \n 2   claim_amount          2000 non-null   object \n 3   amount_paid           1964 non-null   float64\n 4   location              2000 non-null   object \n 5   individuals_on_claim  2000 non-null   int64  \n 6   linked_cases          1974 non-null   object \n 7   cause                 2000 non-null   object \ndtypes: float64(1), int64(3), object(4)\nmemory usage: 125.1+ KB\nNone\nclaim_id                 0\ntime_to_close            0\nclaim_amount             0\namount_paid             36\nlocation                 0\nindividuals_on_claim     0\nlinked_cases            26\ncause                    0\ndtype: int64\n['RECIFE' 'FORTALEZA' 'SAO LUIS' 'NATAL']\n['unknown' 'meat' 'vegetable' ' Meat' 'VEGETABLES']\n"}]},{"source":"Based on information above, there are 2 column with missing value which are _amount_paid_ 36 missing values and _linked_cases_ 26 missing values.\nBesides, there are several column not match with table description, details as below: \n1. _claim_id_ stated as integer, it should be nominal\n2. _claim_amount_ stated as object/nominal, it should be continuous/float\n3. _cause_ inconsistent categorical naming \nBelow are step by step fixing each column using python so all column will be inlined with table description","metadata":{},"cell_type":"markdown","id":"e3fbc6aa-ccbc-4c35-812a-d5d9d42a85a3"},{"source":"# copy df to dfclean # \ndfclean = df\n### 1. column : claim_id ###\n# check uniqueness, change type to nominal\ndfclean=dfclean.astype({'claim_id':'object'})\ndf_claimid = dfclean[['claim_id']]\nprint(df_claimid['claim_id'].value_counts().sort_index(ascending=False)) # no duplicate value \n### 2. column : time_to_close ###\nprint(dfclean.sort_values('time_to_close')) # all positive value \n### 3. column : claim_amount ###\n# change into float64(continuous), 2 decimal place with Brazil currency\nif dfclean['claim_amount'].dtype != 'float64':\n    dfclean['claim_amount'] = dfclean['claim_amount'].map(lambda x: x.lstrip('R$'))\n    dfclean = dfclean.astype({'claim_amount':'float64'})\n### 4.column : amount_paid ### \n# replace missing values with the overall median amount paid \ndfclean['amount_paid'] = dfclean['amount_paid'].fillna(dfclean['amount_paid'].median())\n### 5.column : location ###\n# check uniqueness\nprint(dfclean['location'].unique()) #value match with description \n### 6.column : individuals_on_claim ###\n# need to check minimal value \nprint(dfclean['individuals_on_claim'].min())\n### 7.column : linked_cases ###\n# check uniqueness, replace missing value with unknown \ndfclean['linked_cases'] = dfclean['linked_cases'].fillna(False)\ndfclean['linked_cases'].unique()\n### 8. column: cause ###\n# nominal,check uniqueness, replace missing value with unknown \ndfclean['cause'] = dfclean['cause'].apply(str.lower).str.strip()\ndfclean['cause'] =dfclean['cause'].replace('vegetables','vegetable')\ndfclean['cause'].unique()\n","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1691808054105,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# copy df to dfclean # \ndfclean = df\n### 1. column : claim_id ###\n# check uniqueness, change type to nominal\ndfclean=dfclean.astype({'claim_id':'object'})\ndf_claimid = dfclean[['claim_id']]\nprint(df_claimid['claim_id'].value_counts().sort_index(ascending=False)) # no duplicate value \n### 2. column : time_to_close ###\nprint(dfclean.sort_values('time_to_close')) # all positive value \n### 3. column : claim_amount ###\n# change into float64(continuous), 2 decimal place with Brazil currency\nif dfclean['claim_amount'].dtype != 'float64':\n    dfclean['claim_amount'] = dfclean['claim_amount'].map(lambda x: x.lstrip('R$'))\n    dfclean = dfclean.astype({'claim_amount':'float64'})\n### 4.column : amount_paid ### \n# replace missing values with the overall median amount paid \ndfclean['amount_paid'] = dfclean['amount_paid'].fillna(dfclean['amount_paid'].median())\n### 5.column : location ###\n# check uniqueness\nprint(dfclean['location'].unique()) #value match with description \n### 6.column : individuals_on_claim ###\n# need to check minimal value \nprint(dfclean['individuals_on_claim'].min())\n### 7.column : linked_cases ###\n# check uniqueness, replace missing value with unknown \ndfclean['linked_cases'] = dfclean['linked_cases'].fillna(False)\ndfclean['linked_cases'].unique()\n### 8. column: cause ###\n# nominal,check uniqueness, replace missing value with unknown \ndfclean['cause'] = dfclean['cause'].apply(str.lower).str.strip()\ndfclean['cause'] =dfclean['cause'].replace('vegetables','vegetable')\ndfclean['cause'].unique()\n","outputsMetadata":{"0":{"height":580,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"ed4351b8-667b-4a58-aacd-a28f62a1a37b","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"2000    1\n1999    1\n1998    1\n1997    1\n1996    1\n       ..\n5       1\n4       1\n3       1\n2       1\n1       1\nName: claim_id, Length: 2000, dtype: int64\n     claim_id  time_to_close  ... linked_cases      cause\n356       357             76  ...        False  vegetable\n1747     1748             82  ...        False  vegetable\n286       287             84  ...        False  vegetable\n1976     1977             84  ...        False       meat\n1297     1298             87  ...        False  vegetable\n...       ...            ...  ...          ...        ...\n546       547            419  ...        False    unknown\n1341     1342            427  ...        False    unknown\n469       470            453  ...        False    unknown\n377       378            499  ...        False    unknown\n826       827            518  ...        False    unknown\n\n[2000 rows x 8 columns]\n['RECIFE' 'FORTALEZA' 'SAO LUIS' 'NATAL']\n1\n"},{"output_type":"execute_result","data":{"text/plain":"array(['unknown', 'meat', 'vegetable'], dtype=object)"},"metadata":{},"execution_count":9}]},{"source":"Recheck all the column..","metadata":{},"cell_type":"markdown","id":"d087ce71-7f56-4202-81c3-4a59cf91b911"},{"source":"## make sure amount_paid and claim_amount column in Brazilian currency \npd.options.display.float_format = 'R$ {:.2f}'.format\nprint(dfclean[['amount_paid','claim_amount']])\n## recheck begin\ndfclean.info()\nprint(dfclean.head())\n# check missing value for each column \nprint(dfclean.isna().sum())\n# check uniqueness of categorical column \nprint(dfclean['location'].unique())\nprint(dfclean['cause'].unique())","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1691808054157,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## make sure amount_paid and claim_amount column in Brazilian currency \npd.options.display.float_format = 'R$ {:.2f}'.format\nprint(dfclean[['amount_paid','claim_amount']])\n## recheck begin\ndfclean.info()\nprint(dfclean.head())\n# check missing value for each column \nprint(dfclean.isna().sum())\n# check uniqueness of categorical column \nprint(dfclean['location'].unique())\nprint(dfclean['cause'].unique())","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"038059ae-b171-48da-bdd6-afe5b3621414","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"      amount_paid  claim_amount\n0     R$ 51231.37   R$ 74474.55\n1     R$ 42111.30   R$ 52137.83\n2     R$ 23986.30   R$ 24447.20\n3     R$ 27942.72   R$ 29006.28\n4     R$ 16251.06   R$ 19520.60\n...           ...           ...\n1995  R$ 24265.02   R$ 28982.30\n1996   R$ 4772.77    R$ 5188.44\n1997  R$ 10087.81   R$ 11975.85\n1998  R$ 23310.24   R$ 23516.28\n1999   R$ 6417.92    R$ 8051.40\n\n[2000 rows x 2 columns]\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2000 entries, 0 to 1999\nData columns (total 8 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   claim_id              2000 non-null   object \n 1   time_to_close         2000 non-null   int64  \n 2   claim_amount          2000 non-null   float64\n 3   amount_paid           2000 non-null   float64\n 4   location              2000 non-null   object \n 5   individuals_on_claim  2000 non-null   int64  \n 6   linked_cases          2000 non-null   bool   \n 7   cause                 2000 non-null   object \ndtypes: bool(1), float64(2), int64(2), object(3)\nmemory usage: 111.5+ KB\n  claim_id  time_to_close  ...  linked_cases      cause\n0        1            317  ...         False    unknown\n1        2            195  ...          True    unknown\n2        3            183  ...          True       meat\n3        4            186  ...         False       meat\n4        5            138  ...         False  vegetable\n\n[5 rows x 8 columns]\nclaim_id                0\ntime_to_close           0\nclaim_amount            0\namount_paid             0\nlocation                0\nindividuals_on_claim    0\nlinked_cases            0\ncause                   0\ndtype: int64\n['RECIFE' 'FORTALEZA' 'SAO LUIS' 'NATAL']\n['unknown' 'meat' 'vegetable']\n"}]},{"source":"All missing value gone, and all data seems like already congruent with table description. Since all visualization will be done using Tableau, I'm going to export the clean data to csv\n","metadata":{},"cell_type":"markdown","id":"1fbeb30b-a9b3-40dd-ab43-a2790de78496"},{"source":"dfclean.to_csv(\"food_claims_2212_clean.csv\")","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1691808054206,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"dfclean.to_csv(\"food_claims_2212_clean.csv\")","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"55e93b09-65e0-4f07-ba94-40827fdfbff5","execution_count":11,"outputs":[]},{"source":"## Task 2\n2. Create a visualization that shows the number of claims in each location. Use the visualization to:\n- State which category of the variable location has the most observations\n- Explain whether the observations are balanced across categories of thec variable location","metadata":{},"id":"643d4c36-4183-4fbe-a263-6b9de60d29da","cell_type":"markdown"},{"source":"_Write your answer here_\n![Screenshot 2023-08-11 at 19.45.58](Screenshot%202023-08-11%20at%2019.45.58.png)\n","metadata":{},"id":"1d5ba38c-1b3a-4f9b-bf38-bb0a62dac346","cell_type":"markdown"},{"source":"According to graph above, the most observations location based on percentage claim amount and also total claim amount is **RECIFE** with total claim amount 24 Million (44.40% of total amount) and the least amount location is **NATAL** with the total claim amount 7 Million (14.57 % of total amount). \nOn the other hand, refer to next pie graph, we can see that the observations are imbalanced. Majority individuals on claim is in **RECIFE** 44.11% of total individuals on claim.  ","metadata":{},"cell_type":"markdown","id":"059eace4-1bb7-4c30-aacc-d5b5485e08a4"},{"source":"## Task 3\nDescribe the distribution of time to close for all claims. Your answer must include a visualization that shows the distribution. \n![Screenshot 2023-08-11 at 20.41.54](Screenshot%202023-08-11%20at%2020.41.54.png)\n","metadata":{},"id":"ce5f6df2-fbf2-4c44-9209-9ee668876b53","cell_type":"markdown"},{"source":"# average time_to_close_ all \ntime_to_close = dfclean['time_to_close'].describe()\ntime_to_close.astype('int')","metadata":{"executionCancelledAt":null,"executionTime":46,"lastExecutedAt":1691808054253,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# average time_to_close_ all \ntime_to_close = dfclean['time_to_close'].describe()\ntime_to_close.astype('int')","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"88194d69-5a09-4c0a-9322-3b7e3624fc21","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":"count    2000\nmean      185\nstd        49\nmin        76\n25%       158\n50%       179\n75%       204\nmax       518\nName: time_to_close, dtype: int64"},"metadata":{},"execution_count":12}]},{"source":"Majority time to close for claims are centered between 160-200 days (45.65%/911 claims) of processing, 160-180 days (25.1%) and 181-200 days (20.55%). In sum, around 51.45% (1.029 claims) claims being closed under 180 days.","metadata":{},"id":"8fcff247-db49-42c0-8710-51848aeb6347","cell_type":"markdown"},{"source":"## Task 4\nDescribe the relationship between time to close and location. Your answer must include a visualization to demonstrate the relationship. ","metadata":{},"id":"c5fbe3a0-d277-437c-a1a0-f1edf80684f7","cell_type":"markdown"},{"source":"![graph 5](graph%205.png)\n![Screenshot 2023-08-11 at 21.31.35](Screenshot%202023-08-11%20at%2021.31.35.png)\n\n","metadata":{},"cell_type":"markdown","id":"96916b80-c0eb-4294-b83f-99d6e8b89e6d"},{"source":"The highest percentage of time to close claim for Natal, Recife, and Sao Luis are between 160-180 days (+/- 23%) while for Fortaleza the highest percentage time to close claim is in 180-200 days (23.79%). The most effective location based on time to close claim is Recife with 53.33% claim closed <=180 days (with average population of time closing is 185 days), while the least effective location is Fortaleza since most of cases (>50%) still being processed > 180 days. ","metadata":{},"cell_type":"markdown","id":"0da27d8e-a07f-4c33-b9e1-d3b5363a2cfe"},{"source":"## âœ… When you have finished...\n-  Publish your Workspace using the option on the left\n-  Check the published version of your report:\n\t-  Can you see everything you want us to grade?\n    -  Are all the graphics visible?\n-  Review the grading rubric. Have you included everything that will be graded?\n-  Head back to the [Certification Dashboard](https://app.datacamp.com/certification) to submit your practical exam","metadata":{"tags":[]},"id":"f635131a-00f8-44dd-b610-509db41c1154","cell_type":"markdown"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}